
---
layout: default
title: Advanced Mathematics for Machine learning
Advanced Linear Algebra: Vector spaces, definition and examples
---

This page contains auxiliar material for this course. It contains definitions about concepts that are supplementary and optional for the EoML course. It only means for the curious reader and it does not need to be read for the course sake.

It contains advanced concepts for ML like vector spaces, linear independence, basis, basis transformation and matrix decomposition. 

## Vector spaces

A vector space is a really important definition in Linear Algebra and machine learning but sometimes hard to understand and grasp. I will try to explain it in a very simple and intuitive way but skipping a lot of details. We will start with a simple example. Let's say that we got two vectors $\mathbf{v}_1 = [1, 1] \in \mathbbb{R}^{2}$ and $\mathbf{v}_2 = [1, 2]  \in \mathbbb{R}^{2}$. These vectors are a placeholder for two different `features` or we can call them `dimentions`, thus we say that these features belong to the $ \in \mathbbb{R}^{2}$ space. That means that these features lives in the space where all two-dimensional vectors that take real values live. That space can be easily represented by the cartesian space as such:

<p align="center">
  <img src="images/vectors.png" alt="Sublime's custom image"/>
</p>

### Vector sub-spaces

## Linear independence

## Basis and Rnak

## Linear mappings

## Basis change

## Affine spaces

## Affine mappings